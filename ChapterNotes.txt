Chapter 1 --> Arrays and Strings

Hash Table --> A hash table is a data structure that maps keys to values for highly efficient lookup. 
   A simple implementation example, we use an array of linked lists and a hash code function.
   1. Compute hash code for "Keys". (note: two different key can have same hash code)
   2. Map hash code with index of array using some approach {example, hash(key) % array_length}
   3. At every index there will be linked list of keys and values.

   Hence, To retrieve the value pair by its key, you repeat this process. Compute the hash code from the key, and then
   compute the index from the hash code. Then, search through the linked list for the value with this key.

   The worst case runtime is O(N), where N is the number of keys. This could be because of high collision for two different keys with the same hash code, or two different hash codes that map to the same index.
   A good implementation that keeps collisions to a minimum would have runtime O(1).

   Alternative approach is hash table with a balanced binary search tree, runtime would be O (log N). The advantage is potentially using less space, as no need of large Array and iteration over keys can be in ordered in somecases.

--> Arraylist / Resizable Array --> An Arraylist is resizable array, while still providing O(1) runtime access. A typical implementation
is that when the array is full, the array doubles in size. Each doubling takes 0(N) time, but happens so rarely that its amortized insertion time is still  O(1). "resizing factor" can be different in different languages.

** very imp data structure for interview.

--> StringBuilder --> concatenating a list of strings
On each concatenation, a new copy of the string is created, and the two strings are copied over, character by character.
The total time therefore is O(x + 2x + . . . + nx). This reduces to O(xn2).

Why is it O(xn2)? --> Because 1 + 2 + ... + n equals n(n+1)/2, or O(n2).

--> StringBuilder can help you avoid.this problem. StringBuilder simply creates a resizable array of all the strings, copying them back to a string only when necessary.

A good exercise to practice strings, arrays, and general data structures is to implement your own version of
StringBuilder, HashTable and Array List.

Additional Reading: Hash Table Collision Resolution (pg 636), Rabin-Karp Substring Search (pg 636).

Ch 2 --> Linked List 

Linked list represent sequence of Nodes. 
Single linked list --> each node point to next node in the list
Doubly LL --> each node points to both next node and previous node in the list.

No constant time element access in LL. means, to find Kth element we need to iterate through K element.
Hence, time constant is O(N), but space constant is O(1) {Need to check this concept}.

Benefit of LL --> you can add and remove items from the begining of LL in constant time. This is useful for many specific applications.

Important thing to remember ---> 1. to check for NULL pointer, 2. to update the head or tail pointer as necessary

Runner Technique in Linked list --> Use of two pointers simultaneously to iterate through list and these pointers are dependent on each other. (for example, one pointer moves one step forward and hence the other pointer moves 2 steps forward.)

Recursive LL approach --> This approach takes O(N) space, where N is depth of recursive call.
Recursive algorithm means, making a call iteratively.

Chapter 3 --> Stacks and Queues

Stacks --> stack data structure is precisely what it sounds like: a stack of data.
A stack uses LIFO (last-in first-out) ordering. similar to, a stack of dinner plates.
In certain types of problems, it can be favorable to store data in a stack rather than in an array.

It uses the following operations:
pop ( ) : Remove the top item from the stack.
push ( i tern): Add an item to the top of the stack.
peek(): Return the top of the stack.
is Empty (): Return true if and only if the stack is empty.

Unlike an array, a stack does not offer constant-time access to the i th item. However, it does allow constant time adds and removes, as it doesn't require shifting elements around.

A stack can be implemented using a linked list or an arraylist.
** Stacks are mostly useful for recursive algorithms. 

Queue --> A queue implements FIFO (first-in first-out) ordering. (example, same as a line or queue at a ticket stand)
It uses the operations:
add ( i tern): Add an item to the end of the list.
remove (): Remove the first item in the list.
peek ( ) : Return the top of the queue.
is Empty(): Return true if and only if the queue is empty.

A queue can also be implemented with a linked list. In fact, they are essentially the same thing, as long as items are added and removed from opposite sides.

**** It is especially easy to mess up the updating of the first and last nodes in a queue. Be sure to double check this.

** queues are often used is in breadth-first search or in implementing a cache.

Chapter 4 --> Trees and Graphs
Searching a tree is more complicated than searching in a linearly organized data structure such as an array or linked list.
Additionally, the worst case and average case time may vary wildly, and we must evaluate both aspects of any algorithm.
you must learn it to become fluent in this.

Trees / Type of Trees -->  A tree is actually a type of graph, but not all graphs are trees. Simply put, a tree is a connected graph without cycles.
A tree is a data structure composed of nodes. Below is common scenario of a tree:

1. Each tree has a root node. (Actually, this isn't strictly necessary in graph theory, but it's usually how we use trees in programming, and especially programming interviews.)
2. The root node has zero or more child nodes.
3. Each child node has zero or more child nodes, and so on.

The tree cannot contain cycles. The nodes may or may not be in a particular order, they could have any data type as values, and they may or may not have links back to their parent nodes. 

Tree and graph questions are very common with ambiguous details and incorrect assumptions. Be sure to watch out and check details.

Tree vs Binary Tree --> 
A binary tree is a tree in which each node has up to two children. Not all trees are binary trees.
If a tree has three child node than that becomes ternary tree.
it can be even more, For example, suppose you were using a tree to represent a bunch of phone numbers. In this case, you might use a 10-ary tree, with each node having up to 10 children (one for each digit).

** A node is called a "leaf" node if it has no children.

Binary Tree vs. Binary Search Tree --> 
A binary search tree is a binary tree in which every node fits a specific ordering property: all left descendents <= n < all right descendents. This must be true for each node n.

**** The definition of a binary search tree can vary slightly with respect to equality. Under some definitions, the tree cannot have duplicate values. In others, the duplicate values will be on the right or can be on either side. All are valid definitions, but you should clarify this with your interviewer.

Hence, A binary search tree imposes the condition that, for each node, its left descendents are less than or equal to the current node, which is less than the right descendents.

Balanced vs. Unbalanced --> Not all trees are always balanced. Make sure about this in your question.
A "balanced" tree really means something more like "not terribly imbalanced:". It's balanced enough to ensure O(log n) times for insert and search, but it's not necessarily as balanced as it could be.

Two common types of balanced trees are red-black trees (pg 639) and AVL trees (pg 637), discussed later.

Complete Binary Trees --> 
A complete binary tree is a binary tree in which every level of the tree is fully filled, except for perhaps the last level. To the extent that the last level is filled, it is filled left to right.

Full Binary Trees --> 
A full binary tree is a binary tree in which every node has either zero or two children. That is, no nodes have only one child.

Perfect Binary Trees -->  (perfect trees are rare in interviews and in real life)
A perfect binary tree is one that is both full and complete. All leaf nodes will be at the same level, and this level has the maximum number of nodes.

Binary Tree Traversal --> 

In-Order Traversal --> means to "visit" (often, print) the left branch, then the current node, and finally, the right branch.
When performed on a binary search tree, it visits the nodes in ascending order (hence the name "in-order").

Pre-Order Traversal --> Pre-order traversal visits the current node before its child nodes (hence the name "pre-order"). the root is always the first node visited.

Post-Order Traversal --> Post-order traversal visits the current node after its child nodes (hence the name"post-order"). the root is always the last node visited.

Binary Heaps - (Min Heaps and Max Heaps) -->
Min heaps and Max heaps are same, except in max heaps the elements are in descending order rather than ascending order.

A min-heap is a complete binary tree, means totally filled other than right most element in the last level. Also, each node is smaller than its children. The root, therefore, is the minimum element in the tree.

two key operations on a min-heap: insert and extract_min

Insert --> always start by inserting the element at the bottom. Then, we "fix"the tree by swapping the new element with its parent, until we find an appropriate spot for the element. This takesO(log n) time,where n is the number of nodes in the heap.

Extract_Min --> it's always at the top most element. This algorithm will also take O(log n)time.

Question - How to remove min element.
Answer --> First, we remove the minimum element and swap it with the last element in the heap (the bottommost, rightmost element). Then, we bubble down this element, swapping it with one of its children until the min heap property is restored.

Tries (Prefix Trees) --> Very imp data structure for interviews
A trie is a variant of an n-ary tree in which characters are stored at each node. Each path down the tree may represent a word.
The * nodes (sometimes called "null nodes") are often used to indicate complete words. This is a special type of child implementation.
(such as a TerminatingTrieNode, which inherits from TrieNode). Or, we could use just a boolean flag terminates within the "parent" node.

Number of Node can be calculated as -->
--> anywhere from 1 through ALPHABET SIZE + 1 children, OR
--> 0 through ALPHABET SIZE if a boolean flag is used instead of a* node.

** commonly, a trie is used to store the entire (English) language for quick prefix lookups. Hence, it can be used quickly to check a valid words.
While a hash table can quickly look up whether a string is a valid word, it cannot tell us if a string is a prefix of any valid words. A trie can do this very quickly.
A trie time consistency = 0( K) time, where K is the length of the string.
This is actually the same runtime as a hash table.
Although, mostly Hash table runtime considered as O(1) but its not entirely true, Hence in case of word lookup Hash table has to read through all the K characters of input word, and makes its runtime as O(K).

Most of the time we pass around a reference to the current node in the tree and directly lookup the actual lookup word, looking for * node or boolean flag node.

Graphs --> A graph is simply a collection of nodes with edges between (some of) them.
A tree is actually a type of graph, but not all graphs are trees. Simply put, a tree is a connected graph without cycles.

Two types of Graph --> 
Directed --> directed edges are like a one-way street
Undirected --> undirected edges are like a two-way street
--> The graph might consist of multiple isolated subgraphs. If there is a path between every pair of vertices (or nodes), it is called a "connected graph."
--> The graph can also have cycles (or not). An "acyclic graph" is one without cycles.

*** In tree, you can't necessarily reach all the nodes from a single node.

In Programming, two common ways to represent a graph -->

1. Adjacency List -->  most common way to represent a graph. Every vertex (or node) stores a list of adjacent vertices.
In an undirected graph, an edge like (a, b) would be stored twice: once in a's adjacent vertices and once in b's adjacent vertices.

You don't necessarily need any additional classes to represent a graph. An array (or a hash table) of lists (arrays, arraylists, linked lists, etc.) can store the adjacency list.

simple code example:- 
1 class Graph {
2 public Node[] nodes ;
3 }
4
5 class Node {
6 public String name;
7 public Node[] children;
8 }

2. Adjacency Matrices --> An adjacency matrix is an NxN boolean matrix (where N is the number of nodes), where a true value at 
matrix[i] [j] indicates an edge from node i to node j. (You can also use an integer matrix with Os and 1s.)

In an undirected graph, an adjacency matrix will be symmetric. In a directed graph, it will not (necessarily) be.

*** Adjacency List is somewhat more efficient then Adjacency Matrix, because in Adjacency Matrix you will need to iterate through all the nodes to identify a node's neighbors.

Graph Search --> two most common ways are (DFS - depth-first search and BFS - breadth-first search)

depth-first search (DFS) --> we start at the root (or another arbitrarily selected node) and explore each branch completely before moving on to the next branch. That is, we go deep first before we go wide.

breadth-first search (BFS) --> we start at the root (or another arbitrarily selected node) and explore each neighbor before going on to any of their children. That is, we go wide before we go deep.
BFS is not recursive. Instead, it uses a queue. You can think of this as searching level by level.

*** If you are asked to implement BFS, the key thing to remember is the use of the queue. The rest of the algorithm
flows from this fact.

DFS is often preferred if we want to visit every node in the graph. Although, both works fine.
However BFS is generally better, if we want to find the shortest path (or just any path) between two nodes.

Bidirectional Search --> This is used to find the shortest path between a source and destination node. It operates by essentially running two simultaneous BFS, one from each node. When their searches collide, we have found a path.

** Need to read this chapter again and few Additional Reading: Topological Sort (pg 632), Dijkstra's Algorithm (pg 633), AVL Trees (pg 637), RedBlackTrees (pg 639).
